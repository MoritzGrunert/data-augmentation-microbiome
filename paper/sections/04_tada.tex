\chapter{Tada}
~\cite{sayyari2014}
\begin{itemize}
\item TADA modelliert zwei Arten von Variationen.
    \begin{itemize}
        \item (i) True variation (TV): (biologische variation) Aufgrund biologischer Prozesse variiert die wahre mikrobielle Zusammensetzung zwischen Individuen, selbst wenn sie ähnliche Merkmale aufweisen (z. B. gesund/krank).
        \item (ii) Sampling variation (SV): (technische variation) Aufgrund von Probenahme-, DNA-Extraktions- und Sequenzierungstechniken variiert die gemessene mikrobielle Zusammensetzung selbst für dieselbe biologische Probe.
    \end{itemize}
\item Von den beiden Variationsformen ist die True Variation deutlich schwieriger statistisch zu modellieren.
\item Störfaktoren sind größtenteils unbekannt, ebenso wie die Ursache natürlicher oder zeitlicher Schwankungen.
\item Phylogenetische Struktur
    \begin{itemize}
        \item Die Mikroorganismen einer Probe sind alle Nachkommen eines gemeinsamen Vorfahren, wie ihr phylogenetischer Baum zeigt.
        \item ein phylogenetischer Baum kann sowohl die Verwandtschaftsverhältnisse (in seiner Topologie) als auch die Distanz zwischen den Arten darstellen. 
        \item Enge phylogenetische Beziehungen zwischen OTUs korrespondieren mit Ähnlichkeit im Sequenzraum und möglicherweise auch in funktionellen Rollen.
    \end{itemize}

\item 2.2.2 Generativ model: mixtures
    \begin{itemize}
        \item das oben beschriebene Modell ist eingeschränkt.
        \item Es ignoriert die Tatsache, dass Individuen mehreren Klassen angehören (deren Identifizierung das Ziel ist) und dass innerhalb jeder Klasse Störfaktoren eine weitere Strukturierung der Stichproben bewirken können.
        \item Beispielsweise können wir gesunde und kranke Stichproben für unsere Hauptklassen haben, und innerhalb jeder dieser Klassen können die Stichproben weiter nach Alter, Geschlecht, Gewicht oder anderen Faktoren (die möglicherweise nicht bekannt sind) differenziert werden.
        \item deshalb wird Phänotypstruktur der Stichproben nicht modelliert. Um die Phänotypstruktur zu erfassen, verwenden wir ein Mischungsmodell.
        \item Im generativen Prozess wird jede Stichprobe zunächst gemäß den Clusterwahrscheinlichkeiten einem Cluster zugeordnet, und anschließend wird das oben beschriebene Verfahren durchgeführt.
    \end{itemize}
\item 2.2.3 Data augmentation procedure
    \begin{itemize}
        \item Daher verwenden wir das generative Modell nicht für die Inferenz, sondern lediglich als Werkzeug zur Datenerweiterung für das Training von ML-Modellen.
        \item TADA-SV 
        \item 
    \end{itemize}
\end{itemize}

\begin{algorithm}[H]
\caption{DBS (No-Tree-SV): Distribution-Based Sampling}
\label{alg:dbs}
\begin{algorithmic}[1]
\For{each sample $s \in X$}
    \State $c \leftarrow$ OTU counts of sample $s$
    \State $N \leftarrow \sum_i c_i$

    \State Estimate relative abundances:
    \State \hspace{0.5cm} $p \leftarrow \dfrac{c + \alpha}{\sum_i (c_i + \alpha)}$
    \For{$j = 1$ to $k$}
        \State Draw synthetic counts:
        \State \hspace{0.5cm} $c' \sim \text{Multinomial}(N, p)$
        \State Add $c'$ as a new synthetic sample
    \EndFor
\EndFor

\State \Return original samples and all synthetic samples
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{DBS (No-Tree-SV)}
\begin{algorithmic}
\For{each sample $s$}
    \State $p \gets (c + \alpha) / \sum(c + \alpha)$
    \For{$j = 1$ to $k$}
        \State $c' \sim \text{Multinomial}(N, p)$
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{DBS (No-Tree-SV): Distribution-Based Sampling}
\label{alg:dbs}
\begin{algorithmic}[1]
\Require OTU table $X \in \mathbb{N}^{m \times n}$, number of synthetic samples $k$, smoothing parameter $\alpha$
\Ensure Augmented OTU table $X'$

\For{each sample $s \in X$}
    \State $c \leftarrow$ OTU counts of sample $s$
    \State $N \leftarrow \sum_i c_i$
    \State Estimate relative abundances:
    \State \hspace{0.5cm} $p \leftarrow \dfrac{c + \alpha}{\sum_i (c_i + \alpha)}$
    \For{$j = 1$ to $k$}
        \State Draw synthetic counts:
        \State \hspace{0.5cm} $c' \sim \text{Multinomial}(N, p)$
        \State Add $c'$ as a new synthetic sample
    \EndFor
\EndFor
\State \Return original samples and all synthetic samples
\end{algorithmic}
\end{algorithm}

\[
\mathbf{c} = [10, 20, 30, 40, 50]
\]

\[
N = \sum_i c_i = 150
\]

\[
\mathbf{p} = \frac{\mathbf{c}}{N}
           = \left[ \frac{10}{150}, \frac{20}{150}, \frac{30}{150},
                    \frac{40}{150}, \frac{50}{150} \right]
           = [0.067, 0.133, 0.200, 0.267, 0.333]
\]

\[
\mathbf{c}' \sim \text{Multinomial}(150, \mathbf{p})
\]

\[
\mathbf{c}' = [12, 19, 35, 40, 44]
\]